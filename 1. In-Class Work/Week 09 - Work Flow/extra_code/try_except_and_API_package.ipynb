{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15dd410a-a02b-4f39-bbed-205145b8be3b",
   "metadata": {},
   "source": [
    "# Using a package\n",
    "\n",
    "The code below uses the python [ntscraper](https://github.com/bocchilorenzo/ntscraper) library, which provides a simple set of commands to scrape tweets and social media profiles from the Twitter back-end Nitter. (Note that nitter could go down at pretty much any moment, and even now this runs very slowly!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85846b4-34cf-4034-81d5-16edf9ea35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ntscraper import Nitter\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e1e82-2f1b-4fc0-b7e9-11605dae8811",
   "metadata": {},
   "source": [
    "We start with a list of congressional X handles from [this github](https://github.com/unitedstates/congress-legislators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1eafd8a-1acd-4ae2-9510-66fc31938f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = pd.read_json('https://unitedstates.github.io/congress-legislators/legislators-social-media.json')\n",
    "socials = [i.get('twitter') for i in handles['social']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1207683d-ca9d-4718-a03d-fd58d3db455a",
   "metadata": {},
   "source": [
    "Start by making a directory to hold the tweets data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a86a588a-2bb1-4c0f-a99e-97cf4c653ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('congress_tweets', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61b912-8109-404a-bad8-f4fb4475ef22",
   "metadata": {},
   "source": [
    "Then we'll set up our scraper and initialize an \"errors\" counter tha we can use to break the loop if we keep encountering errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480c4035-2991-4d45-9ade-f156ff6ede5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|█████████████████████████████████████████████████████████████████| 6/6 [00:04<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "scraper = Nitter(log_level=1, skip_instance_check=False)\n",
    "errors = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16821e-ff1a-44c1-b074-ed3afb6f5aea",
   "metadata": {},
   "source": [
    "Finally, we'll run the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00addc4c-a4ae-4cd2-b0dc-c850bd718704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for current_handle in socials:\n",
    "    filename = \"congress_tweets/\" + current_handle +\".json\"\n",
    "    if os.path.exists(filename):\n",
    "        else: \n",
    "            print(\"profile already scraped\")\n",
    "            next\n",
    "    try: \n",
    "        print(\"retrieving data for \" + current_handle)\n",
    "        # only scraping 20, but could be increased to get up to 800 or so\n",
    "        member_tweets = scraper.get_tweets(current_handle, mode='user', instance='https://nitter.privacyredirect.com', number=20, max_retries=1)\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(member_tweets, f, ensure_ascii=False, indent=4)\n",
    "        clear_output() \n",
    "    except:\n",
    "        print(\"error attempting to reconnect\")\n",
    "        scraper = Nitter(log_level=1, skip_instance_check=False)\n",
    "        errors = errors + 1\n",
    "    finally: \n",
    "        if errors > 20:\n",
    "            print(\"max errors exceeded, quitting\")\n",
    "            break\n",
    "    time.sleep(1)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877b436-75d7-49b5-b441-1e6621e0f39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
