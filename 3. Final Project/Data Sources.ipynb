{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cdf517-0d82-4fe5-910f-41cc914e072e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Some free APIs that you could consider for this course\n",
    "\n",
    "This is by no means an exhaustive list! I'm a political scientist, and my selections here reflect that bias. If you're not interested in that, then you should go looking for an alternative. There are lots of freely available APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c49f38-8302-4d88-b872-e5db5c7f1155",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "These sources have Application Programming Interfaces that you can access from Python. Some of them may have a Python \"wrapper\" that simplifies the process of gathering data from them and putting it into a data frame. I've listed some of the more useful ones here, but keep in mind that many legislatures, government agencies, or international organizations offer an API now, so don't treat this as a definitive list.\n",
    "\n",
    "[Check this list of free APIs](https://github.com/public-apis/public-apis). Some of them are novelties (I don't think you can really do a viable project with the catfacts API) but many of them are excellent options for outside-the-box projects.\n",
    "\n",
    "-   [Data.gov](https://api.data.gov/): A single API key that works for multiple U.S. federal government data APIs. There are tons of options here.\n",
    "\n",
    "-   [BLS](https://www.bls.gov/developers/): U.S. Bureau of Labor Statistics\n",
    "\n",
    "-   [FRED](https://fred.stlouisfed.org/docs/api/fred/): Federal Reserve Bank of St. Louis. A wide variety of economic indicators (some overlap with BLS data here, but in a format that I think is much easier to navigate)\n",
    "\n",
    "-   [UCDP](https://ucdp.uu.se/) : Global data on violent conflict and protest. Updates yearly.\n",
    "\n",
    "-   [ACLED](https://apidocs.acleddata.com/) : Global coverage of Violent conflict and protest. Updates weekly.\n",
    "\n",
    "-   [Congress.gov](https://gpo.congress.gov/) : U.S. Congress. Data on bills, members, committees, etc. \n",
    "\n",
    "-   [UK Parliament](https://developer.parliament.uk/): (really, lots of legislative bodies have an API now, I won't list them all here)\n",
    "\n",
    "-   [World Bank](https://datatopics.worldbank.org/world-development-indicators/) (especially development indicators) are a good source for cross-national data on things like GDP, literacy, etc.\n",
    "\n",
    "-   [Manifestos Project](https://manifesto-project.wzb.eu/information/documents/api): Party Manifestos from across the world. Many of these have been split by sentence and then each statement has been manually categorized by topic. \n",
    "\n",
    "-   [OECD](https://data.oecd.org/api/) : Mostly economic data on OECD member states.\n",
    "\n",
    "-   [Spotify](https://developer.spotify.com/documentation/web-api) This requires an access token. You can see a guide for how this might be used at https://medium.com/@maxtingle/getting-started-with-spotifys-api-spotipy-197c3dc6353b\n",
    "\n",
    "\n",
    "\n",
    "## Social Media\n",
    "\n",
    "(Be warned: collecting data from these sources may be a bit more complicated than some of the more user-friendly options above, and they may become unusable in the near future)\n",
    "\n",
    "In the recent past we probably would have spent more time working on collecting data from social media, but in the last few years the most popular platforms have gotten rid of or seriously restricted access for non-commercial users. However, there are (as of this writing) a few sites that are still relatively amenable to this kind of research if you're interested in pursuing it. \n",
    "\n",
    "\n",
    "-   [Bluesky API](https://atproto.blue/en/latest/readme.html) Bluesky allows anyone with an account to access their API and they currently have extremely high rate limits. There's a bit of a learning curve with this one, but feel free to reach out if you want some help getting started.\n",
    "\n",
    "-   [Reddit](https://www.reddit.com/dev/api) (see [here](https://www.jcchouinard.com/reddit-api-without-api-credentials/) for an example of how this might work)\n",
    "\n",
    "-   [nitter, a javascript free mirror of Twitter](https://nitter.net/) went down in 2024, but came back online in early 2025. [There's a Python package](https://github.com/bocchilorenzo/ntscraper) that will help you retrieve data from the site.\n",
    "\n",
    "\n",
    "## APIs with wrapper packages\n",
    "\n",
    "There are Python wrappers for some widely used APIs that can simplify or automate parts of the process of setting up queries or processing data. For example:\n",
    "\n",
    "- [wgbapi](https://blogs.worldbank.org/en/opendata/introducing-wbgapi-new-python-package-accessing-world-bank-data) For the World Bank API\n",
    "- [LyricsGenius](https://lyricsgenius.readthedocs.io/en/master/) for the Genius Lyrics API\n",
    "- [census](https://pypi.org/project/census/) for the Census API\n",
    "- [gdeltdoc](https://github.com/alex9smith/gdelt-doc-api) for the Global Database of Events Language and Tone\n",
    "- [nba_api](https://pypi.org/project/nba_api/) an interface to the NBA stats API\n",
    "\n",
    "Keep in mind that these are basically just a collection of functions that send HTTP requests, they may simplify your life, but they don't do anything you don't already know how to do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6c65b-4fc8-4c08-99f6-a60fcda827cd",
   "metadata": {},
   "source": [
    "# Tips on finding a website to scrape\n",
    "\n",
    "If you're interested in going the webscraping route, I would suggest looking for a site that is going to be reasonably easy to scrape. Simpler is better! Some sites may even have a \"simplified version for slow connections\", these are going to be much easier compared to sites that have really complicated HTML. Also keep in mind that sites that require you to enter a password or login are generally not going to be amenable to web scraping. \n",
    "\n",
    "If you're planning to scrape text data, then you want to look for a site where you can get a lot of links. The websites for major news outlets are always a good option. Blogs and press release pages can also be good: for instance, every member of the U.S. Senate has a website, and most of them will post press releases on a somewhat regular basis and these will usually have a consistent html structure that you can parse.\n",
    "\n",
    "## Using a sitemap\n",
    "\n",
    "Larger sites will usually have a sitemap that acts as a map of URLs to make it easier to web crawlers to index pages. For instance, the Associated Press has a map for\n",
    "<a href=https://apnews.com/ap-sitemap-202410.xml>stories from October 2024 here</a> (this will probably load slowly!)\n",
    "\n",
    "If a sitemap exists, you can usually find a link to it on the sites `robots.txt` page. Here's what that looks like for the AP: https://apnews.com/robots.txt\n",
    "\n",
    "I can use the sitemap to create a list of links, write a scraper that can extract the text from each page, and then create a loop that will extract the relevant text data from each article. I've included an example of doing this for a handful of articles below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6c8c46-156d-42f5-81b0-1f1aeaeb35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import lxml\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1342273-7f71-4394-a932-522a9aaa7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sitemap\n",
    "october_sitemap = get('https://apnews.com/ap-sitemap-202410.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d228c0-c615-44b4-a008-97448ccf7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the content as an XML document\n",
    "sitemap= BeautifulSoup(october_sitemap.content, features=\"xml\")\n",
    "\n",
    "# select all <loc> nodes that are descendants of a url node\n",
    "url_nodes = sitemap.select('url loc')\n",
    "\n",
    "# loop through the entire list and just get the link\n",
    "urls = [i.get_text() for i in url_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c3418-d99d-4d25-a806-4de7d6ba370d",
   "metadata": {},
   "source": [
    "The links here contain a bunch of different article types, but maybe I only want the articles and not any of the links to video links or 'hubs'. I can use a regular expression to detect the urls that have \"article\" as part of their path and create a list with only these links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446cca2c-8a4d-4bab-a3e2-84c7c52e35f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://apnews.com/article/2024-china-open-medvedev-monfils-extraordinary-photo',\n",
       " 'https://apnews.com/article/2024-catalonia-castells-human-tower-extraordinary-photo',\n",
       " 'https://apnews.com/article/2024-czech-republic-miner-extraordinary-photo',\n",
       " 'https://apnews.com/article/2024-cuba-power-outage-fisherman-light-extraordinary-photo',\n",
       " 'https://apnews.com/article/greece-migration-european-union-policy-6e4dff2bb4e88a4c24d6dd056f7f6b22']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_urls = []\n",
    "[article_urls.append(i) if bool(re.search(\"/article/\", i)) else ''  for i in urls]\n",
    "article_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ab25cd-f8f4-4cd7-aec4-8e60ef4fa3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://apnews.com/article/2024-china-open-med...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://apnews.com/article/2024-catalonia-cast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://apnews.com/article/2024-czech-republic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://apnews.com/article/2024-cuba-power-out...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://apnews.com/article/greece-migration-eu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  headline  article_text\n",
       "0  https://apnews.com/article/2024-china-open-med...       NaN           NaN\n",
       "1  https://apnews.com/article/2024-catalonia-cast...       NaN           NaN\n",
       "2  https://apnews.com/article/2024-czech-republic...       NaN           NaN\n",
       "3  https://apnews.com/article/2024-cuba-power-out...       NaN           NaN\n",
       "4  https://apnews.com/article/greece-migration-eu...       NaN           NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.DataFrame(article_urls, columns = ['url'])\n",
    "\n",
    "articles[\"headline\"] = np.nan\n",
    "articles[\"article_text\"] = np.nan\n",
    "\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74a2ce-99c4-45cc-a750-425f12685506",
   "metadata": {},
   "source": [
    "Now I would just need to write a loop to visit each of these urls, extract the information I'm interested in, and put the result in a dataframe. As a courtesy, you probably should also try to limit the frequency of your requests. A simple way to do this is to put a `time.sleep()` function inside your loop, which will cause it to pause for a number of seconds after each iteration.\n",
    "\n",
    "In the interest of speeding things along, I'm just going to grab the first 5 urls here, but ideally we would want to capture everything and then store it somewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c307a-d998-45f9-b2c6-ce8768947457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(5):\n",
    "    # visit url i\n",
    "    req = get(articles['url'][i])\n",
    "    # extract the html\n",
    "    article= BeautifulSoup(req.content)\n",
    "    # get the headline and place it in row i\n",
    "    articles.loc[i, \"headline\"] = ' '.join([str(i.get_text()) for i in article.select(\"h1.Page-headline\")])\n",
    "    # get the text and place it in row i \n",
    "    articles.loc[i, \"article_text\"] = ' '.join([str(i.get_text()) for i in article.select(\".Page-storyBody p\")])\n",
    "    # pause for one second after each iteration of the loop:\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cd96c-cbf0-4893-8781-ad156f643104",
   "metadata": {},
   "source": [
    "Once this runs, I should have article text and headlines in my data frame. Which I can now use for further analysis. (Note: I would probably also want to write some code to get the publication date and maybe the author name here as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f0eb20-fb9c-4fb6-a33a-d3ed214a6fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://apnews.com/article/2024-china-open-med...</td>\n",
       "      <td>An AP photographer focuses his camera on peopl...</td>\n",
       "      <td>BEIJING (AP) — Over the past two and a half de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://apnews.com/article/2024-catalonia-cast...</td>\n",
       "      <td>An AP photographer gets the light just right f...</td>\n",
       "      <td>TARRAGONA, Spain (AP) — Associated Press photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://apnews.com/article/2024-czech-republic...</td>\n",
       "      <td>In one portrait, an AP photographer tells the ...</td>\n",
       "      <td>STONAVA, Czech Republic (AP) — AP photographer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://apnews.com/article/2024-cuba-power-out...</td>\n",
       "      <td>In storm and blackout, an AP photographer find...</td>\n",
       "      <td>HAVANA, Cuba (AP) — Ramon Espinosa started wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://apnews.com/article/greece-migration-eu...</td>\n",
       "      <td>4 people die in a migrant boat accident off a ...</td>\n",
       "      <td>ATHENS, Greece (AP) — Four people, including t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://apnews.com/article/2024-china-open-med...   \n",
       "1  https://apnews.com/article/2024-catalonia-cast...   \n",
       "2  https://apnews.com/article/2024-czech-republic...   \n",
       "3  https://apnews.com/article/2024-cuba-power-out...   \n",
       "4  https://apnews.com/article/greece-migration-eu...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  An AP photographer focuses his camera on peopl...   \n",
       "1  An AP photographer gets the light just right f...   \n",
       "2  In one portrait, an AP photographer tells the ...   \n",
       "3  In storm and blackout, an AP photographer find...   \n",
       "4  4 people die in a migrant boat accident off a ...   \n",
       "\n",
       "                                        article_text  \n",
       "0  BEIJING (AP) — Over the past two and a half de...  \n",
       "1  TARRAGONA, Spain (AP) — Associated Press photo...  \n",
       "2  STONAVA, Czech Republic (AP) — AP photographer...  \n",
       "3  HAVANA, Cuba (AP) — Ramon Espinosa started wor...  \n",
       "4  ATHENS, Greece (AP) — Four people, including t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa85e542-e35f-4cec-8122-8bbd212d6879",
   "metadata": {},
   "source": [
    "## Sites that are difficult to scrape\n",
    "\n",
    "In general, you won't be able to scrape sites that require you to login. You also might find its difficult (although not impossible) to scrape sites that have a lot of interactivity or animations. Often we'll get around these problems by using a package like [Selenium](https://selenium-python.readthedocs.io/) to automate a web browser, but this is a more complicated undertaking compared to just sending `get` requests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f5c29-f334-47ca-83e1-cb731d510385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
